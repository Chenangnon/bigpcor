% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bigpcor.R
\name{bigpcor}
\alias{bigpcor}
\title{Pairwise Partial Correlations}
\usage{
bigpcor(
  x,
  y = NULL,
  z = NULL,
  data = NULL,
  use = "everything",
  method = c("pearson", "spearman", "kendall"),
  blocksize = NULL,
  cl = parallel::getDefaultCluster(),
  chunk.size = NULL,
  verbose = FALSE,
  ...
)
}
\arguments{
\item{x, y}{integer vector, or vector of labels (column names of \code{data} as
returned by \link[base]{colnames}(\code{data})), or matrix or data frame giving
variables whose partial correlations are desired.

Unlike for \link[stats]{cor}, the default for \code{y} (i.e. \code{NULL}) is not
generally equivalent to \code{y = x}. Here, \code{y = NULL} is equivalent to
\code{y = x} only when \code{data} is not \code{NULL} (see section "Details").

When \code{data} is specified and not \code{NULL}, \code{x} must be an integer
vector or a vector of labels; and \code{y} must also be one of an integer vector, a
vector of labels, or \code{NULL}; both \code{x} and \code{y}, when not
\code{NULL}, giving column indices/labels indicating variables in \code{data}.}

\item{z}{integer vector, vector of labels (column names of \code{data}),
or matrix or data frame. \code{z} specifies the conditioning set for
computing partial correlations. When \code{data} is specified and not
\code{NULL}, \code{z} must be an integer vector, or a vector of labels,
or \code{NULL}.

Note that \code{z = NULL} does not correspond to an empty conditioning set,
but rather conditioning on all other variables in \code{x} and \code{y}, i.e.
\code{z = NULL} is equivalent to \code{z = c(x, y)} when \code{data} is not
\code{NULL}. An empty conditioning set corresponds to marginal correlation,
consider the \R routine \link[stats]{cor} for that purpose, or use, for
instance, the function \link[propagate]{bigcor} of library \code{propagate}
for very large datasets.}

\item{data}{matrix or data frame. When specified and not \code{NULL},
\code{x}, \code{y} and \code{z} are interpreted as column indices or labels
(column names of \code{data}) of corresponding numeric variables in \code{data}.
In this case, \code{x} must be an integer vector or a vector of labels, and
each of \code{y} and \code{z} must also be an integer vector, vector of
labels, or \code{NULL}.}

\item{use}{an optional character string giving a method for computing
correlations in the presence of missing values. This must be (an abbreviation
of) one of the strings \code{"everything"}, \code{"all.obs"},
\code{"complete.obs"}, \code{"na.or.complete"}, or \code{"pairwise.complete.obs"}.}

\item{method}{a character string indicating which correlation coefficient
is to be computed. One of \code{"pearson"} (default), \code{"kendall"}, or
\code{"spearman"}: can be abbreviated.}

\item{blocksize}{the size of sub-matrices for block-wise calculation of
large covariance matrices (see argument \code{size} of the function
\link[propagate]{bigcor} of library \code{propagate}). Defaults to 2000.}

\item{cl}{a cluster object, created by package \code{parallel} or package
\code{snow}. Defaults to the registered default cluster obtained as
\code{cl = parallel::getDefaultCluster()}. Only used when \code{z} is not
\code{NULL}.}

\item{chunk.size}{scalar number, number of units for scheduling parallel
tasks. Only used when \code{cl} is a proper cluster object.}

\item{verbose}{logical. If \code{TRUE}, information is printed in the
console when running on a large data matrix (100 variables or more).}

\item{...}{additional argument passed to or from other methods. Currently not
used.}
}
\value{
A matrix of partial correlations, rows corresponding to \code{x} and
columns to \code{y} (replaced by \code{x} if \code{NULL}). The
returned matrix has two named attributed:
\itemize{
\item \code{S}: the size of the used conditioning set;
\item \code{rank}: the matrix rank of the used conditioning set.
}
}
\description{
Calculate partial correlations between elements of two sets of variables
(\code{x} and \code{y}) conditioning on another set of variables (\code{z}),
e.g. confounders to control for.
}
\details{
Partial correlations express the specific portion of variance explained after
controlling for the effect of possible confounding variables when assessing
the correlation between two variables \insertCite{kim2015ppcor}{bigpcor}.

The function takes advantage of:
\itemize{
\item{}{function \link[propagate]{bigcor} from library \code{propagate}
\insertCite{Spiess2018propagate}{bigpcor} to compute covariance matrix
for large datasets (100 variables or more);}
\item{}{linear algebra (\insertCite{khan2008updating;textual}{bigpcor}'s
formula for rank-1 update of inverse of inner product) to efficiently
compute partial correlations by reducing repeated matrix inverse
computations to one inversion and then simpler matrix and vector
multiplications.}
}

The conditioning set considered to compute partial correlations depends on
the specified arguments \code{x}, \code{y}, and \code{z}.

\itemize{
\item{\code{x} and \code{z} are specified: }{\code{bigpcor} returns partial
correlations \code{cor(x_i,y_j)} given all variables (columns) in \code{z}
(or the corresponding columns in \code{data}). If \code{y = NULL},
\code{y = x} is used. Specifying \code{z = c(x, y)} is equivalent to
\code{z = NULL} only when \code{data} is not \code{NULL} and \code{x} and
\code{y} are integer vectors or vectors of labels.}
\item{Only \code{x} and \code{y} are specified: }{\code{bigpcor} returns
partial correlations \code{cor(x_i,y_j)} given all other variables (columns)
in \code{x} and \code{y}. Specifying \code{y = x} is equivalent to
\code{y = NULL} only when \code{data} is not \code{NULL} and \code{x} and
\code{y} are integer vectors or vectors of labels (indeed, duplicates
appearing in both the pair and the conditioning set can be removed in this
case). In the general case, since only pairs with one element in \code{x}
and the other in \code{y} are considered, appropriately specifying \code{x}
and \code{y} can help avoid computing all pairwise partial correlations
between all variables (in \code{x} and \code{y}) if only a subset is desired.}
\item{Only \code{x} is specified: }{\code{bigpcor} returns partial correlations
\code{cor(x_i,x_j)} between columns of \code{x} (\code{x_i} and \code{x_j}
are respectively the \code{i}th and \code{j}th columns of \code{x}, or the
corresponding columns in \code{data}) given all other variables (columns)
in \code{x}.}
}

When \code{x,y,z} are column indices (numeric vectors), they must be
\code{"integers"} (checked using \code{floor(x) == x}). When \code{x,y,z}
are column indices or column labels of \code{data} (column names \code{data}
as returned by \link[base]{colnames}), duplicates are removed from each set
using the function \link{unique}. Thus, to avoid unnecessarily dealing with
singular matrix inversion, we recommend to specify the argument \code{data}
and give \code{x}, \code{y} and \code{z} as column indices or labels.
}
\examples{
# This example mimicks the selection of confounders of gene expressions
# in a genomic network. We consider a simulated data with 50 genes ('fiftygenes').

#* Task: compute pairwise partial correlations between expressions on one hand
# and candidate confouders on the other hand, conditioning on genetic variants.

#* Set number of genetic variants (q), genes (p) and confounders (u) in the
# dataset 'fiftygenes'
p <- q <- 50
u <- 100

#* Using 'bigpcor'
Time <- system.time({
  res <- bigpcor (x = fiftygenes[, (q+1):(q+p)],
                  y = fiftygenes[, (q+p+1):(q+p+u)],
                  z = fiftygenes[, 1:q])
})

# A glance at the results for the first five genes and five confounders
res[1:5, 1:5]

# Elapsed time (seconds)
Time

# Library 'ppcor' is required to run the remaining of the example

\donttest{
##* Comparing 'bigpcor' with a repeated call to 'pcor' of library "ppcor"
# Install 'ppcor' if not installed
if (!"ppcor" \%in\% rownames(installed.packages()))
  install.packages('ppcor', dependencies = TRUE)
require(ppcor)

# Define a function to disable the display of warnings from 'ppcor::pcor'
# This is Martin Maechler's 'tryCatch.W.E' which catches and saves both errors
# and warnings, and in the case of a warning, also keeps the computed result.
catch.conditions <- function (expr) {
  W <- NULL
  w.handler <- function(w) {
    W <<- w
    invokeRestart("muffleWarning")
  }
  list(value = withCallingHandlers(tryCatch(expr, error = function(e) e),
                                  warning = w.handler), warning = W)
}

#* Use the 'pcor' function of library "ppcor"
# The following took about 5 seconds on a MAC OS Ventura 13.4.1 system with 16 GB RAM
W.E. <- catch.conditions({
  Time0 <- system.time({
    res0 <- apply(expand.grid(E = (q+1):(q+p), C = (q+p+1):(q+p+u)),# Combinations of E and C
                  MARGIN = 1,
                  FUN = function(x) { # call 'ppcor::pcor'
                    pcor (fiftygenes[, c(x, 1:q)])$estimate[1,2]
                  })
  })
})

# Run the following to display catched warning(s)
# W.E.$warning # Not run

# Organize res0 into a matrix (rows for genes and columns for confounders)
res0 <- matrix(res0, nrow = p, ncol = u, byrow = FALSE)

# A glance at the results for the first five genes and five confounders
res0[1:5, 1:5]

# Compare results to 10 decimal places
sum(round(res, 10) != round(res0, 10)) # zero means no difference

Time0
Time0[3]/Time[3] # 'bigpcor' is about four fold faster than 'ppcor' in this example
}


}
\references{
\insertAllCited{}
}
\seealso{
\link[ppcor]{spcor} of library \code{ppcor} for semi partial correlations,
\link[stats]{cor} for marginal correlation,
and \link[propagate]{bigcor} of library \code{propagate} for marginal
correlations from large datasets.
}
